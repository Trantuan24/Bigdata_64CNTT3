# Word Count Analysis vá»›i MapReduce

## ğŸ“‹ MÃ´ táº£ bÃ i toÃ¡n

Thá»‘ng kÃª táº§n suáº¥t xuáº¥t hiá»‡n cá»§a cÃ¡c tá»« trong bÃ i bÃ¡o tiáº¿ng Viá»‡t, sá»­ dá»¥ng ká»¹ thuáº­t MapReduce vá»›i data cleaning pipeline hoÃ n chá»‰nh.

### Input Data:
- **raw_article.txt**: BÃ i bÃ¡o gá»‘c tá»« VnExpress 
- **cleaned_article.txt**: Text Ä‘Ã£ lÃ m sáº¡ch 
- **Format**: Plain text tiáº¿ng Viá»‡t cÃ³ dáº¥u

### Output:
- Danh sÃ¡ch táº§n suáº¥t cÃ¡c tá»« sáº¯p xáº¿p theo thá»© tá»± giáº£m dáº§n
- Thá»‘ng kÃª tá»•ng quan vá» táº§n suáº¥t tá»«

## ğŸ—ï¸ Kiáº¿n trÃºc MapReduce

### Map Phase:
- **Input**: DÃ²ng text tá»« file Ä‘Ã£ lÃ m sáº¡ch
- **Logic**: 
  - Tokenize text thÃ nh cÃ¡c tá»« riÃªng biá»‡t
  - Loáº¡i bá» tá»« ngáº¯n hÆ¡n 2 kÃ½ tá»±
  - Emit `(word, 1)` cho má»—i tá»«
- **Output**: Key-Value pairs vá»›i tá»« lÃ m key, count = 1

### Reduce Phase:
- **Input**: Táº¥t cáº£ cáº·p (word, 1) Ä‘Ã£ Ä‘Æ°á»£c group theo word
- **Logic**: 
  - TÃ­nh tá»•ng count cho má»—i tá»«
  - Sáº¯p xáº¿p theo táº§n suáº¥t giáº£m dáº§n
- **Output**: `(word, total_count)` Ä‘Ã£ sáº¯p xáº¿p

## ğŸ“ Cáº¥u trÃºc Project
```
word_count_analysis/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_article.txt           # BÃ i bÃ¡o gá»‘c tá»« VnExpress
â”‚   â”œâ”€â”€ cleaned_article.txt       # Text Ä‘Ã£ lÃ m sáº¡ch
â”‚   â””â”€â”€ article_metadata.json     # Metadata (URL, title, stats)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawler.py               # Crawl bÃ i bÃ¡o tá»« VnExpress
â”‚   â”œâ”€â”€ text_cleaner.py          # Vietnamese text cleaning pipeline
â”‚   â”œâ”€â”€ mapper.py                # Map phase logic
â”‚   â””â”€â”€ reducer.py               # Reduce phase logic
â”œâ”€â”€ output/                      # Káº¿t quáº£ output tá»« Hadoop
â”œâ”€â”€ run_hadoop_wordcount.sh      # Script cháº¡y MapReduce trÃªn Hadoop
â””â”€â”€ README.md                    # TÃ i liá»‡u nÃ y
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Crawl bÃ i bÃ¡o má»›i:
```bash
cd src/
python3 crawler.py
```

### 2. LÃ m sáº¡ch text:
```bash
python3 text_cleaner.py
```

### 3. Cháº¡y MapReduce trÃªn Hadoop:
```bash
chmod +x run_hadoop_wordcount.sh
./run_hadoop_wordcount.sh
```

## ğŸ“Š Káº¿t quáº£ máº«u

```
Word            Count
----            -----
nvidia          16
Ä‘iá»‡n         16
openai          13
trong           13
cÃ´ng           12
cá»§a           11
sáº½            11
vÃ              10
cÃ³             9
tÆ°             9

========================================
SUMMARY STATISTICS
========================================
Total unique words: 371
Total word occurrences: 846
Highest frequency: 16
Lowest frequency: 1
Average frequency: 2.28
```

## ğŸ”§ YÃªu cáº§u há»‡ thá»‘ng

- Python 3.6+
- Hadoop 3.x (cho cháº¿ Ä‘á»™ Hadoop)
- Bash shell
- requests, beautifulsoup4 (cho crawler)
- bc calculator (cho thá»‘ng kÃª)

## ğŸ“ˆ TÃ­nh nÄƒng

- âœ… Crawl tá»± Ä‘á»™ng bÃ i bÃ¡o tá»« VnExpress
- âœ… Data cleaning hoÃ n chá»‰nh cho tiáº¿ng Viá»‡t
- âœ… Cháº¡y MapReduce trÃªn Hadoop cluster
- âœ… Thá»‘ng kÃª táº§n suáº¥t tá»« chi tiáº¿t
- âœ… Format output Ä‘áº¹p vÃ  dá»… Ä‘á»c
- âœ… Error handling vÃ  logging
- âœ… Tá»± Ä‘á»™ng upload/download tá»« HDFS
- âœ… Xá»­ lÃ½ text tiáº¿ng Viá»‡t cÃ³ dáº¥u
- âœ… Real-world data tá»« VnExpress

## ğŸ› Troubleshooting

### Lá»—i phá»• biáº¿n:
1. **File input khÃ´ng tá»“n táº¡i**: Cháº¡y `crawler.py` vÃ  `text_cleaner.py` trÆ°á»›c
2. **Permission denied**: `chmod +x run_hadoop_wordcount.sh`
3. **Hadoop not found**: Kiá»ƒm tra `HADOOP_HOME` vÃ  `PATH`
4. **requests/beautifulsoup4 not found**: `pip3 install requests beautifulsoup4`

### Logs:
- Hadoop: Check Hadoop logs táº¡i `/opt/hadoop/logs/`
- YARN: Web UI táº¡i `http://localhost:8088`

## ğŸ—‚ï¸ ÄÆ°á»ng dáº«n HDFS vÃ  Monitoring

### HDFS File System:
```
/user/ubuntu/wordcount/
â”œâ”€â”€ input/
â”‚   â””â”€â”€ cleaned_article.txt       # Input data uploaded tá»« local
â””â”€â”€ output/
    â”œâ”€â”€ _SUCCESS                  # Marker file bÃ¡o job thÃ nh cÃ´ng
    â””â”€â”€ part-00000               # Káº¿t quáº£ thá»±c tá»« MapReduce
```

### Web UI Monitoring:
- **HDFS NameNode**: http://localhost:9870
  - Xem file system: Utilities â†’ Browse the file system
  - ÄÆ°á»ng dáº«n: `/user/ubuntu/wordcount/`
- **YARN ResourceManager**: http://localhost:8088
  - Theo dÃµi MapReduce jobs
  - Xem logs vÃ  metrics

### CÃ¡ch Download Output tá»« Hadoop:
```bash
# Xem files trÃªn HDFS
hdfs dfs -ls /user/ubuntu/wordcount/output

# Download káº¿t quáº£ vá» local
hdfs dfs -get /user/ubuntu/wordcount/output/part-00000 ./result.txt

# Hoáº·c xem trá»±c tiáº¿p trÃªn HDFS
hdfs dfs -cat /user/ubuntu/wordcount/output/part-00000
```

## ğŸ“ Ghi chÃº ká»¹ thuáº­t

- Sá»­ dá»¥ng plain text format cho input/output
- Data cleaning pipeline cho tiáº¿ng Viá»‡t cÃ³ dáº¥u
- Tokenization Ä‘Æ¡n giáº£n: split by whitespace
- Hadoop Streaming API Ä‘á»ƒ cháº¡y Python scripts
- Tá»± Ä‘á»™ng upload input vÃ  download output
- Error handling cho text khÃ´ng há»£p lá»‡



