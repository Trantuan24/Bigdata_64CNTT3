#!/bin/bash
"""
Script cháº¡y Energy Consumption Analysis trÃªn Hadoop
TÃ¬m nhá»¯ng nÄƒm cÃ³ giÃ¡ trá»‹ Average > 30
"""

# Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$SCRIPT_DIR"
SRC_DIR="$PROJECT_DIR/src"
DATA_DIR="$PROJECT_DIR/data"

echo "ğŸ­ Energy Consumption Analysis - Hadoop MapReduce"
echo "================================================"

# Kiá»ƒm tra Hadoop
if ! command -v hadoop &> /dev/null; then
    echo "âŒ Hadoop khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y. Kiá»ƒm tra HADOOP_HOME vÃ  PATH"
    exit 1
fi

# Kiá»ƒm tra file input
INPUT_FILE="$DATA_DIR/energy_data.csv"
if [ ! -f "$INPUT_FILE" ]; then
    echo "âŒ KhÃ´ng tÃ¬m tháº¥y file input: $INPUT_FILE"
    echo "ğŸ’¡ Cháº¡y data generator trÆ°á»›c:"
    echo "   cd $SRC_DIR && python3 data_generator.py"
    exit 1
fi

# Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n HDFS
HDFS_INPUT_DIR="/user/$(whoami)/energy_consumption/input"
HDFS_OUTPUT_DIR="/user/$(whoami)/energy_consumption/output"
LOCAL_OUTPUT_DIR="$PROJECT_DIR/output"

echo "ğŸ“‚ Chuáº©n bá»‹ dá»¯ liá»‡u trÃªn HDFS..."

# XÃ³a thÆ° má»¥c cÅ© náº¿u cÃ³
hdfs dfs -rm -r -f "$HDFS_INPUT_DIR" "$HDFS_OUTPUT_DIR"

# Táº¡o thÆ° má»¥c input trÃªn HDFS
hdfs dfs -mkdir -p "$HDFS_INPUT_DIR"

# Upload file input lÃªn HDFS
hdfs dfs -put "$INPUT_FILE" "$HDFS_INPUT_DIR/"

echo "âœ… ÄÃ£ upload dá»¯ liá»‡u lÃªn HDFS"
echo "ğŸ“Š Sá»‘ records: $(wc -l < "$INPUT_FILE")"

# Hiá»ƒn thá»‹ preview dá»¯ liá»‡u
echo ""
echo "ğŸ“‹ Preview dá»¯ liá»‡u input:"
head -6 "$INPUT_FILE" | column -t -s ','

# Cháº¡y Hadoop MapReduce job
echo ""
echo "ğŸ”„ Cháº¡y Hadoop MapReduce job..."

hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \
    -files "$SRC_DIR/mapper.py","$SRC_DIR/reducer.py" \
    -mapper "python3 mapper.py" \
    -reducer "python3 reducer.py" \
    -input "$HDFS_INPUT_DIR/energy_data.csv" \
    -output "$HDFS_OUTPUT_DIR"

if [ $? -ne 0 ]; then
    echo "âŒ Hadoop MapReduce job tháº¥t báº¡i!"
    exit 1
fi

echo "âœ… Hadoop MapReduce job hoÃ n thÃ nh!"

# Táº£i káº¿t quáº£ vá» local
echo ""
echo "ğŸ“¥ Táº£i káº¿t quáº£ vá» local..."
mkdir -p "$LOCAL_OUTPUT_DIR"

hdfs dfs -get "$HDFS_OUTPUT_DIR/part-00000" "$LOCAL_OUTPUT_DIR/high_consumption_years.txt"

# Hiá»ƒn thá»‹ káº¿t quáº£
echo ""
echo "ğŸ“Š Káº¾T QUáº¢ ENERGY CONSUMPTION ANALYSIS"
echo "====================================="
echo ""

# Hiá»ƒn thá»‹ káº¿t quáº£ tá»« file
cat "$LOCAL_OUTPUT_DIR/high_consumption_years.txt"

echo ""
echo "ğŸ“ File káº¿t quáº£: $LOCAL_OUTPUT_DIR/high_consumption_years.txt"

# Thá»‘ng kÃª tá»« káº¿t quáº£
RESULT_FILE="$LOCAL_OUTPUT_DIR/high_consumption_years.txt"
if [ -f "$RESULT_FILE" ]; then
    # Äáº¿m sá»‘ nÄƒm (bá» qua header vÃ  summary lines)
    TOTAL_YEARS=$(grep -E "^[0-9]{4}" "$RESULT_FILE" | wc -l)
    
    if [ $TOTAL_YEARS -gt 0 ]; then
        echo ""
        echo "ğŸ“ˆ THá»NG KÃŠ Tá»”NG QUAN"
        echo "==================="
        echo "â€¢ Tá»•ng sá»‘ nÄƒm cÃ³ Average > 30: $TOTAL_YEARS"
        
        # Láº¥y danh sÃ¡ch nÄƒm
        YEARS_LIST=$(grep -E "^[0-9]{4}" "$RESULT_FILE" | awk '{print $1}' | tr '\n' ', ' | sed 's/,$//')
        echo "â€¢ CÃ¡c nÄƒm: $YEARS_LIST"
        
        # TÃ­nh giÃ¡ trá»‹ cao nháº¥t vÃ  tháº¥p nháº¥t
        HIGHEST=$(grep -E "^[0-9]{4}" "$RESULT_FILE" | awk '{print $2}' | sort -nr | head -1)
        LOWEST=$(grep -E "^[0-9]{4}" "$RESULT_FILE" | awk '{print $2}' | sort -n | head -1)
        
        echo "â€¢ Má»©c tiÃªu thá»¥ cao nháº¥t: $HIGHEST"
        echo "â€¢ Má»©c tiÃªu thá»¥ tháº¥p nháº¥t (>30): $LOWEST"
        
        # TÃ­nh trung bÃ¬nh
        AVG=$(grep -E "^[0-9]{4}" "$RESULT_FILE" | awk '{sum += $2; count++} END {printf "%.2f", sum/count}')
        echo "â€¢ Trung bÃ¬nh cÃ¡c nÄƒm Ä‘Æ°á»£c filter: $AVG"
    else
        echo ""
        echo "ğŸ“ˆ THá»NG KÃŠ: KhÃ´ng cÃ³ nÄƒm nÃ o cÃ³ Average > 30"
    fi
fi

echo ""
echo "âœ… HoÃ n thÃ nh Energy Consumption Analysis trÃªn Hadoop!"

# Hiá»ƒn thá»‹ HDFS info
echo ""
echo "ğŸ—‚ï¸  HDFS Paths:"
echo "â€¢ Input: $HDFS_INPUT_DIR"
echo "â€¢ Output: $HDFS_OUTPUT_DIR"

# Hiá»ƒn thá»‹ Web UI links
echo ""
echo "ğŸŒ Web UI Monitoring:"
echo "â€¢ HDFS NameNode: http://localhost:9870"
echo "â€¢ YARN ResourceManager: http://localhost:8088"

echo ""
echo "ğŸ¯ BÃ i toÃ¡n: TÃ¬m nhá»¯ng nÄƒm cÃ³ giÃ¡ trá»‹ Average > 30"
echo "ğŸ“Š Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: $LOCAL_OUTPUT_DIR/high_consumption_years.txt"
